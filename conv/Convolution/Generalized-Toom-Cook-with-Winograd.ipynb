{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy.signal as scisig\n",
    "\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Previously we implemented 1D and 2D convolution using Winograd. We saw the potential $2 \\times$ savings of it compared to the direct method. Here, we seek to generalize the size of the filter and ouput of the FIR tap $F(m,r)$ using the previous work of Toom-Cook.\n",
    "\n",
    "\n",
    "### F(2,3)\n",
    "\n",
    "We define the matrices below for our bilinear algorithm\n",
    "\n",
    "$$Y = A^T \\Big[(Gg) \\odot (B^Td) \\Big]$$\n",
    "\n",
    "The algorithm seeks to solve\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "d_0 & d_1 & d_2 \\\\\n",
    "d_1 & d_2 & d_3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "g_0 \\\\ g_1 \\\\ g_2 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Here, the input size is $\\alpha = m+r-1$, the filter size is $r$, and the output size is $r$. Winograd showed we only need to compute $\\alpha$ multiplications, which is equivalent to the $\\alpha \\times \\alpha$ matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "B23 = np.asarray([\n",
    "    [1, 0,-1, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0,-1, 1, 0],\n",
    "    [0, 1, 0,-1]\n",
    "]).T\n",
    "\n",
    "G23 = np.asarray([\n",
    "    [ 1,  0, 0],\n",
    "    [.5, .5,.5],\n",
    "    [.5,-.5,.5],\n",
    "    [ 0, 0,  1]\n",
    "])\n",
    "\n",
    "A23 = np.asarray([\n",
    "    [1,1,1,0],\n",
    "    [0,1,-1,-1]\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.7575913666155722e-16\n"
     ]
    }
   ],
   "source": [
    "d = np.random.random(4)\n",
    "g = np.random.random(3)\n",
    "\n",
    "inner = np.dot(G23,g) * np.dot(B23.T,d)\n",
    "y = np.dot(A23.T, inner)\n",
    "\n",
    "direct = np.asarray([sum(d[:3]*g), sum(d[1:]*g)])\n",
    "\n",
    "print(\"Error:\",la.norm(direct - y)/la.norm(direct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this variation, we see the algorithm requires $(24,28)$ flops.\n",
    "\n",
    "### 2D Case \n",
    "\n",
    "The Winograd extended to 2D is\n",
    "\n",
    "$$Y = A^T \\Big[(GgG^T) \\odot (B^TdB) \\Big]A$$\n",
    "\n",
    "The extension to the Hankel case is we need a Doubly Toeplitz Matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "H_1 & H_3 & H_2\\\\\n",
    "H_2 & H_1 & H3 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_3^T \\\\ X_2^T \\\\ X_1^T\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For each entry of the 2D convolved output, it relies on the sum of 1D convolutions. As we move across the rows and columnrs of the output, we convolve as well by selecting different submatrices of the data and filter. The doubly Toeplitz captures this idea. We also need to add a $0$ padding since we convolve \"off\" the data.\n",
    "\n",
    "For more info, here are the [slides](http://www.cs.uoi.gr/~cnikou/Courses/Digital_Image_Processing/Chapter_04c_Frequency_Filtering_(Circulant_Matrices).pdf). We've implemented this code before and will use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of one Winograd 1.655706559043613e-16\n"
     ]
    }
   ],
   "source": [
    "g = np.random.random((4,4))\n",
    "f = np.random.random((3,3))\n",
    "\n",
    "direct = np.zeros((2,2))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        direct[i,j] = np.sum(f * g[i:i+3,j:j+3])\n",
    "        \n",
    "inner = np.dot(G23, np.dot(f, G23.T)) * np.dot(B23.T, np.dot(g, B23))\n",
    "Y = np.dot(A23.T, np.dot(inner, A23))\n",
    "\n",
    "print(\"Error of one Winograd\",la.norm(Y - direct)/la.norm(direct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Winograd Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 8.103783236736365e-17\n",
      "Error: 1.615305964141385e-16\n"
     ]
    }
   ],
   "source": [
    "convLib = scisig.convolve2d(f,g)\n",
    "conv2d = convolve2DToeplitz(f,g)\n",
    "g2 = revMatrix(g)\n",
    "g2 = padImage(g2,len(f))\n",
    "cWino = simpleWinogradAlg(f,g2,2,B23,G23,A23)[0]\n",
    "cWino = revMatrix(cWino)\n",
    "\n",
    "print(\"Error:\",la.norm(convLib - conv2d, ord=2)/la.norm(convLib, ord=2))\n",
    "print(\"Error:\",la.norm(convLib - cWino, ord=2)/la.norm(convLib, ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hankel Representation\n",
    "\n",
    "To restate the Winograd, we propose the Hankel multiplication\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & d_0 \\\\\n",
    "0 & 0 & d_0 & d_1 \\\\\n",
    "0 & d_0 & d_1 & d_2 \\\\\n",
    "d_0 & d_1 & d_2 & d_3 \\\\\n",
    "d_1 & d_2 & d_3 & 0 \\\\\n",
    "d_2 & d_3 & 0 & 0 \\\\\n",
    "d_3 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ g_0 \\\\ g_1 \\\\ g_2 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "As a reduced convolution (only keep the top $n$ terms), this is\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & d_0 \\\\\n",
    "0 & 0 & d_0 & d_1 \\\\\n",
    "0 & d_0 & d_1 & d_2 \\\\\n",
    "d_0 & d_1 & d_2 & d_3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ g_0 \\\\ g_1 \\\\ g_2 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For Winograd, this is further reduced to\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & d_0 & d_1 & d_2 \\\\\n",
    "d_0 & d_1 & d_2 & d_3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ g_0 \\\\ g_1 \\\\ g_2 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3434141  0.27206016]\n",
      "[0.3434141  0.27206016]\n"
     ]
    }
   ],
   "source": [
    "d = np.random.random(4)\n",
    "g = np.random.random(3)\n",
    "g2 = np.append(np.zeros(1),g)\n",
    "direct = np.dot(A23.T,  (np.dot(G23,g) * np.dot(B23.T,d))  )\n",
    "print(direct)\n",
    "\n",
    "H = toeplitzToHankle(vectorToToeplitz(d))[2:4]\n",
    "conv = np.dot(H,g2)\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toom-Cook Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\tilde{V}$ be the low-order evaluation matrix. Let $V^{-1}$ be the interpolation matrix. We recast this problem generally to\n",
    "\n",
    "$$Y = V^{-1} \\Big[(\\tilde{V}g) \\odot (\\tilde{V}d) \\Big]$$\n",
    "\n",
    "This is equivalent to the Hankel form of:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & d_0 \\\\\n",
    "0 & 0 & d_0 & d_1 \\\\\n",
    "0 & d_0 & d_1 & d_2 \\\\\n",
    "d_0 & d_1 & d_2 & d_3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ g_0 \\\\ g_1 \\\\ g_2 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.43787247e-01 4.79244490e-01 3.43414095e-01 2.72060160e-01\n",
      " 5.36882881e-02 5.02780253e-02 3.70074342e-18] \n",
      "\n",
      "2nd to 4th terms: [0.3434141  0.27206016]\n"
     ]
    }
   ],
   "source": [
    "convTC = monomialTC(d,g2[::-1])\n",
    "\n",
    "print(convTC[1],\"\\n\")\n",
    "print(\"2nd to 4th terms:\",convTC[1][2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monomial Toom Cook Bilinear Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3434141  0.27206016]\n"
     ]
    }
   ],
   "source": [
    "V = monoEval(4,False,True)\n",
    "\n",
    "# multiplication\n",
    "mult = np.dot(V,g2[::-1]) * np.dot(V,d)\n",
    "\n",
    "# interpolation\n",
    "V = monoInterp(4,False,True)\n",
    "Vinv = la.inv(V)[2:4]\n",
    "coeff = np.dot(Vinv,mult)\n",
    "\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebyshev Toom-Cook Bilinear Algorithm\n",
    "\n",
    "Below is the 1D case\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & d_0 \\\\\n",
    "0 & 0 & d_0 & d_1 \\\\\n",
    "0 & d_0 & d_1 & d_2 \\\\\n",
    "d_0 & d_1 & d_2 & d_3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "g_0 \\\\ g_1 \\\\ g_2 \\\\ 0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38801489 1.4714925  0.89281228 0.55659847 0.27206016 0.05368829\n",
      " 0.05027803]\n",
      "Minimal Filtering: 4\n",
      "Evaluation Shape: (7, 7)\n",
      "Interpolation Shape: (7, 7)\n"
     ]
    }
   ],
   "source": [
    "g3 = np.append(g, np.zeros(1))\n",
    "\n",
    "n = len(d)\n",
    "assert(n == len(g2))\n",
    "    \n",
    "z = 2*n-1\n",
    "i = np.arange(n, dtype=np.float64)\n",
    "j = np.arange(z, dtype=np.float64)\n",
    "\n",
    "# Chebyshev nodes:\n",
    "t = np.cos((2*j+1)/(2*z)*np.pi)\n",
    "\n",
    "# dim: (nodes, i)\n",
    "V = np.cos(i * np.arccos(t.reshape(-1, 1)))\n",
    "\n",
    "P = np.dot(V,d)\n",
    "Q = np.dot(V,g3[::-1])\n",
    "\n",
    "# multiply\n",
    "R = P*Q\n",
    "\n",
    "# interpolate\n",
    "V = np.cos(j * np.arccos(t.reshape(-1, 1)))\n",
    "Vinv = la.inv(V)[:]*2\n",
    "chebyConv = np.dot(Vinv, R)\n",
    "\n",
    "print(chebyConv)\n",
    "\n",
    "print(\"Minimal Filtering:\",4)\n",
    "print(\"Evaluation Shape:\",V.shape)\n",
    "print(\"Interpolation Shape:\",Vinv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
