{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy.signal as scisig\n",
    "\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Toom-Cook is a generalization for higher-ordered variations of Karatsuba. It multiplied two numbers in near linear time with an exchange of lots of multiplications.\n",
    "\n",
    "### Connection between Convolution and Polynomial Multiplication\n",
    "\n",
    "We are able to relate convolution to multiplication, or polynomial multiplication through this technique as said in [Explicit Cook-Toom Algorithm for Linear Convolution](#).\n",
    "\n",
    "Given a finite sequence of discrete values $f$ and $g$ with respective length $N$ and $M$, where we wish to solve $f \\ast g$. Let $F(x) = poly(f)$ and $G(x) = poly(g)$. Note $poly()$ means represent as a polynomial of degree $X-1$ for $X$ values and not the big-O notation.\n",
    "\n",
    "Let  \n",
    "\n",
    "$$S(x) = F(x)G(x) = \\sum\\limits_{i=0}^{M+N-2}s_ix^i \\textrm{ where } s_i = \\sum\\limits_{m=0}^{N-1}d[m]g[i-m]$$\n",
    "\n",
    "Then $S(x)$ is the polynomial notation of our convolution $f \\ast g$.\n",
    "\n",
    "To verify, consider the convolution of the polynomial $(x+1)^i$, which can be expanded with the binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0: return 1\n",
    "    return n * factorial(n-1)\n",
    "\n",
    "def binomialVec(n):\n",
    "    vec = np.zeros(n+1)\n",
    "    for i in range(n+1):\n",
    "        vec[i] = (factorial(n))/(factorial(n-i) * factorial(i))\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error between convolution and Binomial Thm 0.0\n"
     ]
    }
   ],
   "source": [
    "fp = 3\n",
    "gp = 21\n",
    "\n",
    "f = binomialVec(fp)\n",
    "g = binomialVec(gp)\n",
    "conv = scisig.convolve(f,g)\n",
    "binthm = binomialVec(fp + gp)\n",
    "\n",
    "print(\"Error between convolution and Binomial Thm\", la.norm(binthm - conv, ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Toom-Cook-2,3\n",
    "\n",
    "The Karatsuba Algorithm we have been using is a variation of Toom-2, where we split the polynimial into two (nearly) equal lenghts. Given the polynomials, we seek the product $s(x)$:\n",
    "\n",
    "$$f(x) = f_1x + f_0 \\ | \\ g(x) = g_1x + g_0$$\n",
    "$$s(x) = f_1g_1x^2 + [f_1g_1 - (f_0 - f_1)(g_0 - g_1) + f_0g_0]x + f_0g_0$$\n",
    "\n",
    "and the matrix representation is\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} s_0 \\\\ s_1 \\\\ s_2 \\end{bmatrix} = \n",
    "\\begin{bmatrix} 1 & 0 & 0 \\\\ 1 & -1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} d_0 & 0 & 0 \\\\ 0 & d_0 - d_1 & 0 \\\\ 0 & 0 & d_1 \\end{bmatrix}\n",
    "\\begin{bmatrix} 1 & 0 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} g_0 \\\\ g_1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This requires 3 multiplications and 3 additions vs. 4 multiplicatoions and 2 additions with normal convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of Toom-2: 1.0331693058966458e-16\n"
     ]
    }
   ],
   "source": [
    "# toom-2\n",
    "n = 2**2\n",
    "f = randomvec(n,seedNumber=166)\n",
    "g = randomvec(n,seedNumber=3313)\n",
    "\n",
    "f1 = f[:n//2]; f0 = f[n//2:]\n",
    "g1 = g[:n//2]; g0 = g[n//2:]\n",
    "\n",
    "w2 = np.convolve(f1,g1)\n",
    "w0 = np.convolve(f0,g0)\n",
    "w1 = np.convolve(f0-f1,g0-g1)\n",
    "\n",
    "ans = np.zeros(2*n - 1)\n",
    "ans[:n-1] = w2\n",
    "ans[n//2:n//2+(n-1)] += w0 + w2 - w1\n",
    "ans[n:] += w0\n",
    "conv = np.convolve(f,g)\n",
    "\n",
    "print(\"Error of Toom-2:\",la.norm(conv - ans)/la.norm(conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toom-3 does the same by breaking it into three components [ref](https://gmplib.org/manual/Toom-3_002dWay-Multiplication.html):\n",
    "\n",
    "$$g(x) = f_2x^2 + f_1x + f_0 \\ | \\ g(x) = g_2x^2 + g_1x + g_0$$\n",
    "\n",
    "$$w_0 = \\frac{1}{2}f_0 \\times g_0$$\n",
    "$$w_1 = \\frac{1}{2}(f_2+f_1+f_0) \\times (g_2+g_1+g_0)$$\n",
    "$$w_2 = \\frac{1}{6}(f_2-f_1+f_0) \\times (g_2-g_1+g_0)$$\n",
    "$$w_3 = \\frac{1}{6}(4f_2+2f_1+f_0) \\times (4g_2+2g_1+g_0)$$\n",
    "$$w_4 = f_2 \\times g_2$$\n",
    "\n",
    "$$s(x) = w_4x^4 + (w_0 - w_1 - w_2 + w_3 - 2w_4)x^3 + (-2w_0 + w_1 + 3w_2 + 0w_3 - w_4)x^2 + (-w_0+2w_1-2w_2-w_3+2w_4)x + 2w_0 $$\n",
    "\n",
    "<img src=\"imgs/toom-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "This requires 5 multiplications and 23 additions (of size n/3) vs. 8 multiplications and 16 additions. There are some re-usability techniques to reduce this down to 20 additions if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 5.110200917058224e-16\n"
     ]
    }
   ],
   "source": [
    "# toom-3\n",
    "n = 3**2\n",
    "f = randomvec(n,seedNumber=357)\n",
    "g = randomvec(n,seedNumber=450)\n",
    "\n",
    "f2 = f[:n//3]; f1 = f[n//3:2*n//3]; f0 = f[2*n//3:]\n",
    "g2 = g[:n//3]; g1 = g[n//3:2*n//3]; g0 = g[2*n//3:]\n",
    "\n",
    "w4 = np.convolve(f2,g2)\n",
    "w3 = (1/6) * np.convolve(4*f2 + 2*f1 + f0, 4*g2 + 2*g1 + g0)\n",
    "w2 = (1/6) * np.convolve(f2 - f1 + f0, g2 - g1 + g0)\n",
    "w1 = (1/2) * np.convolve(f2 + f1 + f0, g2 + g1 + g0)\n",
    "w0 = (1/2) * np.convolve(f0,g0)\n",
    "\n",
    "dist = n//3 * 2 - 1\n",
    "ans = np.zeros(2*n - 1)\n",
    "ans[:dist] = w4\n",
    "ans[dist-2:2*dist-2] += w0 - w1 - w2 + w3 - 2*w4\n",
    "ans[2*dist-4:3*dist-4] += -2*w0 + w1 + 3*w2 - w4\n",
    "ans[3*dist-6:4*dist-6] += -w0 + 2*w1 - 2*w2 - w3 + 2*w4\n",
    "ans[-dist:] += 2*w0\n",
    "\n",
    "conv = np.convolve(f,g)\n",
    "\n",
    "print(\"Error:\",la.norm(conv - ans)/la.norm(conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Toom-Cook-k\n",
    "\n",
    "These equalities were derived using a technique published with the Toom-Cook Algorith. Using this algorithm, we can generalize a higher order division using [Toom-Cook-k](http://www.bodrato.it/papers/Madrid2007-Toom-Cook-inGF2x.pdf#page=8). Toom-2, Toom-3, and Toom-k in general can be formulated using a 5 step process:\n",
    "\n",
    "1. Splitting\n",
    "1. Evalulation \n",
    "1. Pointwise Multiplication\n",
    "1. Interpolation\n",
    "1. Recomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToomVandMatrixEval(n):\n",
    "    z = 2*n-1\n",
    "    TV = np.zeros((z,n))\n",
    "    TV[0,0] = 1; TV[-1,-1] = 1\n",
    "    TV[1:-1,:] = np.vander(rs(z-2),N=n,increasing=True)\n",
    "            \n",
    "    return TV\n",
    "\n",
    "def ToomVandMatrixInterp(n):\n",
    "    z = 2*n-1\n",
    "    TV = np.zeros((z,z))\n",
    "    TV[0,0] = 1; TV[-1,-1] = 1\n",
    "    TV[1:-1,:] = np.vander(rs(z-2),N=z,increasing=True)\n",
    "            \n",
    "    return TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.1102230246251565e-16\n",
      "V Stability: 1.9318516525781366 \n",
      "\n",
      "Error: 2.3314683517128287e-15\n",
      "V Stability: 18.57278450177571 \n",
      "\n",
      "Error: 2.6061879543634898e-14\n",
      "V Stability: 778.3319601145967 \n",
      "\n",
      "Error: 4.663970285811754e-13\n",
      "V Stability: 68292.86978826691 \n",
      "\n",
      "Error: 2.1130905832429306e-10\n",
      "V Stability: 10073550.470288064 \n",
      "\n",
      "Error: 2.3575724213089058e-08\n",
      "V Stability: 2233980693.8730702 \n",
      "\n",
      "Error: 3.659320556750872e-05\n",
      "V Stability: 694046478268.3225 \n",
      "\n",
      "Error: 0.013651231992382567\n",
      "V Stability: 287539186151480.3 \n",
      "\n",
      "Error: 3.93673715197686\n",
      "V Stability: 1.5315637702596208e+17 \n",
      "\n",
      "Error: 11575301855709.02\n",
      "V Stability: 1.3517943513600119e+19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(2,12):\n",
    "    f = randomvec(n)\n",
    "    g = randomvec(n)\n",
    "\n",
    "    # evaluation\n",
    "    TV = ToomVandMatrixEval(n)\n",
    "    fEval = np.dot(TV,f)\n",
    "    gEval = np.dot(TV,g)\n",
    "\n",
    "    # multiply in interpolation space\n",
    "    pEval = fEval * gEval\n",
    "\n",
    "    # Interpolation\n",
    "    TVInterpolation = ToomVandMatrixInterp(n)\n",
    "    p = la.solve(TVInterpolation, pEval)\n",
    "\n",
    "    # no recomposition\n",
    "    print(\"Error:\",la.norm(p - np.convolve(f,g)))\n",
    "\n",
    "    # stability\n",
    "    print(\"V Stability:\",la.norm(TVInterpolation,ord=2),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... maybe not the best naively?\n",
    "\n",
    "We know such from the *evaluation* step, which compute a Vandermone matrix vector multiplication, *interpolation* which requires inverting a matrix ($O(n^3)$ steps?) and then calculating a matrix vector product, it becomes clear just constructing the Toom-Cook through the interpolation technique can be quite costly.\n",
    "\n",
    "Without the evaluation and interpolation step, we know this operation can save a lot of multiplications (only requires $M+N-1$, and as observed from Toom-2 and Toom-3). We present the paper's finding for calculating this interpolation faster, using the simpler Lagrangian Interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Toom-Cook Linear Convolution\n",
    "\n",
    "The paper supplied allows us to directly create the additions and multiplications we need.\n",
    "\n",
    "Let $k = L-2 = M+N-3$. The explicit form is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\vdots \\\\\n",
    "w_{L}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & \\dots & 0 \\\\\n",
    "0 & (-1)^{k-1}\\prod\\limits_{i \\ne 1,i=1,\\dots,k}r_i & (-1)^{k-1}\\prod\\limits_{i \\ne 2,i=1,\\dots,k}r_i & \\dots & (-1)^{(k-1)+1}\\prod\\limits_{i=1,\\dots,k}r_i \\\\\n",
    "0 & (-1)^{k-2}\\sum\\limits_{i=1,\\dots,k, i \\ne 1}\\prod\\limits_{j = 1,\\dots,k, j \\ne 1,i}r_i &       (-1)^{k-2}\\sum\\limits_{i=1,\\dots,k, i \\ne 2}\\prod\\limits_{j = 1,\\dots,k, j \\ne 2,i}r_i & \\dots & (-1)^{(k-2)+1}\\sum\\limits_{i=1,\\dots,k}\\prod\\limits_{j = 1,\\dots,k, j \\ne 1,i}r_i  \\\\\n",
    "0 & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 1 & 1 & \\dots & -(\\sum\\limits_{i}^k r_i) \\\\\n",
    "0 & 0 & 0 & \\dots & 1\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "d_0g_0 \\\\\n",
    "\\frac{D(r_1)G(r_1) - d_0g_0}{r_1 \\prod\\limits_{i \\ne 1}(r_1 - r_i)} \\\\\n",
    "\\frac{D(r_2)G(r_2) - d_0g_0}{r_2 \\prod\\limits_{i \\ne 2}(r_2 - r_i)} \\\\\n",
    "\\vdots \\\\ \\vdots \\\\ \n",
    "\\frac{D(r_k)G(r_k) - d_0g_0}{r_k \\prod\\limits_{i \\ne k}(r_k - r_i)} \\\\\n",
    "g_{n-1}d_{n-1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For $r_1, r_2, \\dots r_k$, we choose small nonzeros values like $1,-1,2,-2, \\dots$.\n",
    "\n",
    "Let:\n",
    "\n",
    "$$D(r_i)G(r_i) = (d_0\\cdot (r_i)^0 + d_1\\cdot (r_i)^1 + \\dots) \\ast (g_0\\cdot (r_i)^0 + g_1\\cdot (r_i)^1 + \\dots)$$\n",
    "\n",
    "Look at the [Tensor Formulation](https://github.com/jucaleb4/solomonik_convolution/blob/master/Tensors/Nested-Toom-Cook.ipynb) of this to see it in action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
