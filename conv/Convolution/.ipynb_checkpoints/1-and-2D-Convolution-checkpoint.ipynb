{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from func import *\n",
    "\n",
    "np.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The work here deals with discrete convolution. We will show the application of our work to computing a 1-D Convolution and 2-D Convolution\n",
    "\n",
    "Per Wikipedia\n",
    "\n",
    "```\n",
    "mathematical operation on two functions (f and g) to produce a third function that expresses how the shape of one is modified by the other\n",
    "```\n",
    "\n",
    "![conv](https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif)\n",
    "\n",
    "A metaphor for convolution is given two functions, how do the two interact? We can see the interaction of functions $f$ and $g$ above, we can see the convolution is the percentage of how likely one event is to be the same as another. Read [this blog](http://colah.github.io/posts/2014-07-Understanding-Convolutions/) about the probabilty of a ball landing in a certain spot to get a better understanding.\n",
    "\n",
    "Now that we have a high level understanding of what convolution is, we show there are mainly two types of convolution: 1D and 2D. We will explain each in detail and how it is computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Convolution\n",
    "\n",
    "1D convolution is basically represented in the animation above. It's the convolution of two sets of arrays of data that are both 1D. In our research, we are particularly interested in **discrete** convolution, which takes in a set of discrete values and computes the convolution. The formula is described as:\n",
    "\n",
    "$$\n",
    "{\\displaystyle (f*g)[n]=\\sum _{m=-\\infty }^{\\infty }f[m]g[n-m]}\n",
    "$$\n",
    "\n",
    "This function is essentially performing a sliding window. An animation (although 2D, but still serves the purpose) is shown below\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*ZCjPUFrB6eHPRi4eyP6aaA.gif\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "### Cost\n",
    "\n",
    "Naively, we can see there is a computation cost of convolving $n$ values across a length $m$. So we can bound our cost as $O(nm)$. If $n=m$, then this is $O(n^2)$\n",
    "\n",
    "### Alternative Representations\n",
    "\n",
    "We can model the convolution as a matrix multiplication. Because we are having a sliding-window effect, this can be modeled with a [Toeplitz matrix](https://en.wikipedia.org/wiki/Toeplitz_matrix#Discrete_convolution). However, we naively know a matrix-vector multiplication is still O(n^2).\n",
    "\n",
    "$$h \\ast x = Toeplitz(h) \\times x$$\n",
    "\n",
    "However, because of the special structure of Toeplitz matrices, we claim this can be solves faster. In fact, using the Fast Fourier Transform, this can be solved in about $O(nlogn)$ instead. wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135  0.71518937] [0.417022   0.72032449]\n",
      "[0.22886731 0.69357351 0.51516842]\n",
      "Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "p = 1; n = 2**p\n",
    "\n",
    "x = randomvec(n)\n",
    "hvec = randomvec(n,seedNumber=p)\n",
    "T = vectorToToeplitz(hvec)\n",
    "\n",
    "toeplitzConv = np.dot(T,x)\n",
    "regConv = np.convolve(x,hvec)\n",
    "\n",
    "print(x,hvec)\n",
    "print(regConv)\n",
    "print(\"Error:\",la.norm(toeplitzConv - regConv)/la.norm(regConv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as scisig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing 2D Convolution\n",
    "\n",
    "For a general multidimension convolution, we define it as the (infinite) summation\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\sum _{k_{1}=-\\infty }^{\\infty }\\sum _{k_{2}=-\\infty }^{\\infty }...\\sum _{k_{M}=-\\infty }^{\\infty }h(k_{1},k_{2},...,k_{M})x(n_{1}-k_{1},n_{2}-k_{2},...,n_{M}-k_{M})}\n",
    "$$\n",
    "\n",
    "A generalized 2 dimension case is:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\sum _{k_{1}=-\\infty }^{\\infty }\\sum _{k_{2}=-\\infty }^{\\infty }h(k_{1},k_{2})x(n_{1}-k_{1},n_{2}-k_{2})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alernative Representations\n",
    "\n",
    "Like the one-dimensional case, we seek to represent this as a structured matrix to exploit special features for faster convolution. One way to represent 2D convolution is to use a doubly block Circulant matrix (just a special-case Toeplitz), as shown [here](https://stackoverflow.com/questions/16798888/2-d-convolution-as-a-matrix-matrix-multiplication) and [here](http://www.cs.uoi.gr/~cnikou/Courses/Digital_Image_Processing/Chapter_04c_Frequency_Filtering_(Circulant_Matrices).pdf#page=13).\n",
    "\n",
    "### Doubly Block Toeplitz\n",
    "\n",
    "As we developed 1D linear convolution through a Toeplitz matrix, we can also develop 2D linear convolution through a Toeplitz matrix. \n",
    "\n",
    "Suppose\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix} 1 & 4 & 1 \\\\ 2 & 5 & 3 \\\\ 7 & 2 & 4\\end{bmatrix},\n",
    "H = \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "(If we want to stick to the window-sliding analog, remember to flip the $H$ matrix along the anti-diagonal, as convolution can be the same as a time-dimension flip.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 | 2 2\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray([\n",
    "    [1,4,1],\n",
    "    [2,5,3],\n",
    "    [7,2,4]\n",
    "])\n",
    "\n",
    "H = np.asarray([\n",
    "    [1,1],\n",
    "    [1,-1]\n",
    "])\n",
    "\n",
    "m1,n1 = X.shape\n",
    "m2,n2 = H.shape\n",
    "f1,g1 = (m1+m2-1),(n1+n2-1)\n",
    "\n",
    "print(m1,n1,\"|\",m2,n2)\n",
    "print(f1,g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll suppose a $stride=1$ one as well to make it easier. Let $(M_1,N_1)$ be the dimension of $X$ and $(M_2,N_2)$ be the dimension fo $H$. Then the result of the convolution will be $(M_1 + M_2 - 1, N_1 + N_2 - 1) = (4,4)$.\n",
    "\n",
    "We can pad $H$ with zeros to create this shape:\n",
    "\n",
    "$$H_{pad} = \n",
    "\\begin{bmatrix} \n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 0 & 0 \\\\ \n",
    "1 & -1 & 0 & 0 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We then create separate Toeplitz matrices for each row (building from the bottom up) of $H_{pad}$, to simulate how each row interacts with the element of the $X$.\n",
    "\n",
    "$$\n",
    "H_1 = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "-1 & 1 & 0 \\\\\n",
    "0 & -1 & 1 \\\\\n",
    "0 & 0 & -1\n",
    "\\end{bmatrix},\n",
    "H_2 = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1 \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{bmatrix},\n",
    "H_3 = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix},\n",
    "H_4 = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now we construct the block Circulant (special case of Toeplitz). If we treat each block as the unit, the dimension of the block Toeplitz should be $(N_1,M_1)$.\n",
    "\n",
    "$$\n",
    "\\textbf{H} = \\begin{bmatrix}\n",
    "H_1 & H_4 & H_3 \\\\\n",
    "H_2 & H_1 & H_4 \\\\\n",
    "H_3 & H_2 & H_1 \\\\\n",
    "H_4 & H_3 & H_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We must alter the matrix $X$ to match the dimension of $H$. This is done through a strategy similar to $vec(X)$, except we vectorize starting from the bottom. We define it as $x$:\n",
    "\n",
    "$$\n",
    "x = \n",
    "\\begin{bmatrix}\n",
    "(7 & 2 & 4)^T \\\\\n",
    "(2 & 5 & 3)^T \\\\\n",
    "(1 & 4 & 1)^T\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 7 \\\\ 2 \\\\ 4 \\\\ 2 \\\\ 5 \\\\ 3 \\\\ 1 \\\\ 4 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now perform:\n",
    "\n",
    "$$\\textbf{H}x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H =\n",
      " [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0. -1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "H1 = vectorToToeplitz(N=3,v=np.asarray([1,-1]))[:4]\n",
    "H2 = vectorToToeplitz(N=3,v=np.asarray([1, 1]))[:4]\n",
    "H3 = vectorToToeplitz(N=3,v=np.asarray([0, 0]))[:4]\n",
    "H4 = vectorToToeplitz(N=3,v=np.asarray([0, 0]))[:4]\n",
    "Hlist = np.asarray([H1,H2,H3,H4])\n",
    "\n",
    "Hfull = np.zeros((f1*g1,m1*n1))\n",
    "for i in range(f1):\n",
    "    for j in range(n1):\n",
    "        Hfull[i*f1:(i+1)*f1, j*n1:(j+1)*n1] = Hlist[(i+(f1-1)*j)%f1]\n",
    "        \n",
    "print(\"H =\\n\",Hfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 4 2 5 3 1 4 1]\n"
     ]
    }
   ],
   "source": [
    "# create vectorized matrix\n",
    "def quasiVec(V, blkSize):\n",
    "    m,n = V.shape\n",
    "    return np.reshape(V[::-1], newshape=(m*n,))\n",
    "\n",
    "x = quasiVec(X,m1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Computation\n",
    "\n",
    "With the $\\textbf{H}$ and $x$, after we compute $\\textbf{H}x$, we will have a quasi-vectorized form of our convolution. Remember how we put the last column first in creating the $H$'s and $x$? We must account for that permutation by reversing the blocks of the resultant answer. Once we do that, we return to the matrix form by transposing each block vector and stacking them on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecToConvMatrix(v, shape):\n",
    "    assert(len(shape) == 2)\n",
    "    return np.reshape(v, newshape = shape)[::-1]\n",
    "\n",
    "def createDoublyToeplitz(F,fm,fn,gm,gn):\n",
    "    m = fm+gm-1; n = fn+gn-1\n",
    "    \n",
    "    F2 = np.zeros((m,n)).copy()\n",
    "    F2[m-fm:,:fn] = F.copy()\n",
    "    F = F2\n",
    "    \n",
    "    Fs = np.zeros((m,n,gn))\n",
    "    diffZero = n-fn\n",
    "    \n",
    "    Ts = np.zeros((m,n,gn))\n",
    "    for y in range(m):\n",
    "        smallT = vectorToToeplitz(F[y])[:n,:gn]\n",
    "        Ts[m-y-1] = smallT.copy()\n",
    "    \n",
    "    Tfull = np.zeros((m*n,gm*gn))\n",
    "    for i in range(m):\n",
    "        sel = i\n",
    "        for j in range(gm):\n",
    "            Tfull[i*n:(i+1)*n, j*gn:(j+1)*gn] = Ts[sel]\n",
    "            sel -= 1\n",
    "            if(sel < 0):\n",
    "                sel = m-1\n",
    "                \n",
    "    return Tfull\n",
    "            \n",
    "def convolve2DToeplitz(F,G):\n",
    "    fm,fn = F.shape; gm,gn = G.shape\n",
    "    Tfull = createDoublyToeplitz(F,fm,fn,gm,gn)\n",
    "    g = quasiVec(G,gm)\n",
    "    vecTConv = np.dot(Tfull, g)\n",
    "    m = fm+gm-1; n = fn+gn-1\n",
    "    return vecToConvMatrix(vecTConv, (m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific Error: 0.0\n",
      "General Algorithm Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "vecTConv = np.dot(Hfull,x)\n",
    "toeConv = vecToConvMatrix(vecTConv, (f1,g1))\n",
    "regConv = scisig.convolve2d(H,X)\n",
    "automatedToeConv = convolve2DToeplitz(H,X)\n",
    "\n",
    "print(\"Specific Error:\",la.norm(regConv - toeConv, ord=2)/la.norm(regConv, ord=2))\n",
    "print(\"General Algorithm Error:\",la.norm(regConv - automatedToeConv, ord=2)/la.norm(regConv, ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the General Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.2614176163947098e-16\n"
     ]
    }
   ],
   "source": [
    "fm,fn,gm,gn = np.random.randint(2,25,size=4)\n",
    "fm = fn # square filter\n",
    "f = np.random.random((fm,fn))\n",
    "g = np.random.random((gm,gn))\n",
    "\n",
    "convLib = scisig.convolve2d(f,g)\n",
    "conv2d = convolve2DToeplitz(f,g)\n",
    "\n",
    "print(\"Error:\",la.norm(convLib - conv2d,ord=2)/la.norm(convLib,ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Analysis\n",
    "\n",
    "Ignoring the cost of setting up the problem, the main cost of the algorithm is calculating\n",
    "\n",
    "$$\\textbf{H}\\hat{x}$$\n",
    "\n",
    "where $\\textbf{H}$ is a doubly Toeplitz Matrix. Let the filter $F \\in R^{r,r}$ and the data $G \\in R^{m,n}$. Then $p = m+r-1$ and $q = n+r-1$. Our doubly Toeplitz matrix will be of size $(p \\cdot q) \\times (m \\cdot n)$. Furthermore, the vectorized $\\hat{x}$ is of size $m \\cdot n$.\n",
    "\n",
    "Naive cost would be $\\Theta(mnpq)$.\n",
    "\n",
    "However, because a doubly Toeplitz matrix, we can view it as one Toeplitz matrix. First, we bound the size of the band $b$. Notice we will only have $r$ different Toeplitz blocks. Each of those blocks are of size $R^{q \\times n}$. Thus the band size is bounded by $rq$.\n",
    "\n",
    "Given a vector of size $N = mn$ and band $B = rq$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
